{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbgxEHE6BNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import *\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import random\n",
        "import matplotlib.colors as mcolors\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDFw4t-V-BFP",
        "colab_type": "text"
      },
      "source": [
        "# Clustering Handwriting Samples\n",
        "\n",
        "In this homework, you will be working with the k-Means clustering algorithm that we discussed last week.\n",
        "\n",
        "To start off with you will be using k-means clustering as a classification approach to recognizing handwriten digits, like the ones below:\n",
        "![MNist Handwriting Examples](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
        "\n",
        "The goal is to correctly group together all of the 0s, all of the 1s, etc. Some of these can be tricky! A 3 can look like an 8, or a 7 like a 9!\n",
        "\n",
        "Glance through the code below and then run it -- it contains functions for creating training/testing splits from a dataset, running a classifier, and making plots of your predictions (don't worry too much about understanding the plotting code -- it's a little confusing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzI5lswD8NSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# yet another way of creating train/test splits!\n",
        "def create_train_test_split(data,test_size=0.3):\n",
        "  df = pd.DataFrame(data.data)\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(df, data.target, test_size=test_size)\n",
        "  return np.array(train_data), np.array(test_data), np.array(train_labels), np.array(test_labels)\n",
        "\n",
        "def classify(predictor, train_data, test_data, train_labels=None):\n",
        "  # fit the predictor to our training data\n",
        "  if train_labels is not None:\n",
        "    predictor.fit(train_data, train_labels)\n",
        "  else:\n",
        "    predictor.fit(train_data)\n",
        "  \n",
        "  # make predictions on the testing data\n",
        "  test_predictions = predictor.predict(test_data)\n",
        "\n",
        "  # return our predicted cluster identities and cluster centers\n",
        "  return test_predictions, predictor.cluster_centers_\n",
        "\n",
        "def create_plot(predictor, train_data, test_data):\n",
        "  Z, cluster_centers = classify(predictor, train_data, test_data)\n",
        "\n",
        "  appended = np.vstack([test_data,cluster_centers])\n",
        "  reduced_data = PCA(n_components=3).fit_transform(appended)\n",
        "\n",
        "  reduced_test_data = reduced_data[:test_data.shape[0]]\n",
        "  reduced_centers = reduced_data[test_data.shape[0]:]\n",
        "\n",
        "  possible_colors = np.array(list(mcolors.TABLEAU_COLORS.keys()))\n",
        "  possible_colors[np.linspace(0, possible_colors.shape[0] - 1, 10).astype(int)]\n",
        "\n",
        "  for pt, label in zip(reduced_test_data, Z):\n",
        "    plt.scatter(pt[0],pt[1], color=possible_colors[label], marker='o',alpha=0.25, s=10, linewidths=2)\n",
        "\n",
        "  for pt, label in zip(reduced_centers,range(max(Z)+1)):\n",
        "    plt.scatter(pt[0],pt[1], color=possible_colors[label], marker='+', s=300, linewidths=15,alpha=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYKATHfa4i0T",
        "colab_type": "text"
      },
      "source": [
        "First things first, we need to load the data! Here, I'll load the handwriting data from sklearn using the load_digits() function, and then we'll split that into training and testing data using the function written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4bFW6_M9dam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the MNist Handwriting dataset\n",
        "data = load_digits()\n",
        "train_data, test_data, train_labels, test_labels = create_train_test_split(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWKiV3R_Szp",
        "colab_type": "text"
      },
      "source": [
        "Below, we are going to create two predictors, one that has an \"random\" initialization and one that has an initialization called \"k-means++\".\n",
        "\n",
        "***HOMEWORK QUESTION 1 (5 points):*** Visit the [sklearn documentation for the KMeans predictor](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) that we're using. Read about the difference between these initialization methods. Describe in a short paragraph the difference between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0rXlzsM6zAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters = 10 # we know that there are 10 digits, so we want to have 10 clusters\n",
        "kmeans_random_initialization = KMeans(init='random', n_clusters=n_clusters)\n",
        "kmeans_better_initialization = KMeans(init='k-means++', n_clusters=n_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqJaNJLP_P2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40f59646-3264-4d03-8de6-51da1981786d"
      },
      "source": [
        "random_predictions, random_cluster_centers = classify(kmeans_random_initialization, train_data, test_data, train_labels=train_labels)\n",
        "print('Accuracy: {}'.format(accuracy_score(test_labels, random_predictions)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.0962962962962963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10cMGPghAm9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbcf09d7-f18d-483c-99eb-8b343328680a"
      },
      "source": [
        "better_predictions, better_cluster_centers = classify(kmeans_better_initialization, train_data, test_data, train_labels=train_labels)\n",
        "print('Accuracy: {}'.format(accuracy_score(test_labels, better_predictions)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.18888888888888888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOWMar03Av6D",
        "colab_type": "text"
      },
      "source": [
        "***HOMEWORK QUESTION 2 (10 points): ***Run the classification and accuracy computation for both the random initialization and the better initialization ~10 times each. Report the average accuracy for each. Does one classifier seem better than the other? If so, which, and why do you think that is?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBwkslOF3r8F",
        "colab_type": "text"
      },
      "source": [
        "## Visualization and Dimensionality Reduction\n",
        "\n",
        "I provided you with a function \"create_plot\" which takes in your predictor, and the training data and training labels and creates a plot of them. The code for that plotting is complex, but the general idea is that in order for us to visualize what our predictor is doing, we first need to reduce the dimensionality of the input data. What does that mean?\n",
        "\n",
        "Well, the MNist handwriting digits that we've loaded are images, represented by 64 pixel values, or 64 dimensions. But we can't visualize 64 dimensions on a plot easily! Instead, we want to find a good representation of our data in 2 dimensions (so that we can plot it on an x-y scatter plot).\n",
        "\n",
        "Principal Component Analysis is an approach that finds the most important ways in which your data varies and represents your data with just those dimensions -- so we can take our 64-dimensional images and instead represent them with 2-dimensional points. (Dimensionality reduction is a huge area of work and research in data analysis! Don't worry too much about the details here -- the major takeaway is that the create_plot function lets you make 2D scatter plots of our data, even if it had more dimensions than that to start with.)\n",
        "\n",
        "***HOMEWORK QUESTION 3 (5 points)***: Run the create plot function for both the random initialization and the k-means++ initialization a few times each (the dimensionality reduction has some amount of randomization each run). Paste these visualizations into your homework, labeling them by which initialization was used. Do you notice any significant differences?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azPz8adLGWao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_plot(kmeans_random_initialization, train_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d7pqwIiGY3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_plot(kmeans_better_initialization, train_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNgwaBETCQ0_",
        "colab_type": "text"
      },
      "source": [
        "# HOMEWORK QUESTION 4 (20 points): Putting This Together on Your Own\n",
        "\n",
        "Starting next week, you will be working on your final projects, which involve performing your own data analysis. Thus far, you have largely been running code I write for you an modifying parameters. But now it's time for you to put the pieces together on your own.\n",
        "\n",
        "Below, I load a new dataset for you. It's in the same format at the handwriting digits dataset we loaded up above (except the labels are junk -- this is truly the unsupervised context; we don't know the \"correct\" labels for even our training data).\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "1. Split the data into appropriate training/testing splits\n",
        "2. Train a classifier on your training data, experimenting with different initializations and different numbers of clusters (for the handwriting digits it was obvious that we wanted 10 clusters; here we don't know the appropriate number of clusters).\n",
        "3. Create the scatter plot visualization to help you qualitatively assess which combinations of initializations and numbers of clusters seem most appropraite for your data. Include two visualizations in your report: one showing what you think is the best combination of initializations and number of clusters in your report, and one that you didn't think was as good. Explain why you think your selected parameters are better.\n",
        "\n",
        "Finally, upload both your report and this iPython notebook to your Slack channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrzkifU4UdiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltocGCvS48-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE GOES HERE!"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}